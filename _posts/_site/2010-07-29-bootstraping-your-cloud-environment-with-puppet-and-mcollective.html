<p>This is a “recipe” on how to bootstrap your whole environment in case of a disaster ie. your data center goes dark or if you are migrating from one environment to another. This guide differs from others in that it uses mcollective and DNS to provide you with greater flexibility in deploying and bootstraping environments. Some of the alternate ways are <a href="http://github.com/ripienaar/ec2-boot-init#readme">ec2-boot-init by R.I. Pienaar</a> or Grig Gheorghiu’s <a href="http://agiletesting.blogspot.com/2009/09/bootstrapping-ec2-images-as-puppet.html">Bootstrapping EC2 images as Puppet clients</a>.</p>

<h2 id="intro">Intro</h2>

<p>You will need two disk images, your code repository and your DB backup and you can rebuild your whole environment from scratch in a relatively short period of time. This could be adapted to generic cloud provisioning however use case I’m trying to address is disaster recovery. We are using DNS so that we can keep hostnames consistent between environments ie. mail01 will be a mail server in all environments instead of domU-1-2-3-4 in one, rack-2345 in other etc.</p>

<h2 id="set-up-a-master-node-image">Set up a master node image</h2>

<p>Master node is the node that controls all the other nodes. Most importantly it contains all your configuration management data. You will need to install following</p>

<ul>
  <li>
    <p>mcollective with ActiveMQ</p>
  </li>
  <li>
    <p>DnsMasq</p>
  </li>
  <li>
    <p>Puppet from <a href="http://www.puppetlabs.com/">Puppet Labs</a></p>
  </li>
</ul>

<p>1.  You will need to get a DNS name from a dynamic DNS provider such as DynDNS. Once you have that you will need to write a shell script that runs at boot and sets your EC2 private IP to that DNS name. Let’s say we want our controller station to be known as controller.ec2.domain.com we can do something like this</p>

<pre><code>IP=`facter ipaddress`
change_my_dns_ip controller.ec2.domain.com
# Delete any entries from hosts
sed -i "/controller.ec2.domain.com/d" /etc/hosts
echo "${IP}     controller.ec2.domain.com" &gt;&gt; /etc/hosts
</code></pre>

<ol>
  <li>Set up ActiveMQ to be used with mcollective <a href="http://code.google.com/p/mcollective/wiki/GettingStarted">http://code.google.com/p/mcollective/wiki/GettingStarted</a></li>
  <li>Set up mcollective</li>
</ol>

<p>Configure controller.ec2.domain.com as the stomp host in your mcollective configuration for both client and server configuration.</p>

<p>4.Install dnsmasq. You don’t need to configure anything since by default dnsmasq will read /etc/hosts and serve those names over DNS</p>

<ol>
  <li>
    <p>Install puppetmaster, configure it anyway you want</p>
  </li>
  <li>
    <p>Image it</p>
  </li>
</ol>

<h2 id="set-up-a-genericworker-node-image">Set up a generic/worker node image</h2>

<p>You will need to Install following</p>

<ul>
  <li>
    <p>Mcollective</p>
  </li>
  <li>
    <p>puppet agent</p>
  </li>
</ul>

<ol>
  <li>
    <p>On the worker node you need to configure the server piece of mcollective and make sure the stomp.host is pointed to the master ie.  controller.ec2.domain.com.</p>
  </li>
  <li>
    <p>Create a reboot agent (we’ll discuss later how to use it). Please visit <a href="http://code.google.com/p/mcollective/wiki/SimpleRPCIntroduction">http://code.google.com/p/mcollective/wiki/SimpleRPCIntroduction</a> for an example. Create a new file ie. reboot.rb. Paste this code in it</p>

    <p>module MCollective
  module Agent
   class Reboot&lt;RPC::Agent
     def reboot_action
      <code>/sbin/shutdown -r now</code>
     end
   end
  end
 end</p>
  </li>
</ol>

<p>Copy the resulting file to the mcollective agents directory</p>

<ol>
  <li>
    <p>Add following script to the bootup</p>

    <p>MASTER=<code>host controller.ec2.domain.com | grep address | cut -f4 -d" "</code>
 IS_ALREADY_SET=<code>grep -c ec2.domain.com /etc/resolv.conf</code>
 if [ $IS_ALREADY_SET -lt 1 ]; then   
 sed -i “s/^search .*/search ec2.domain.com/g” /etc/resolv.conf
 sed -i “s/^nameserver/nameserver ${MASTER}\nnameserver/g” /etc/resolv.conf
 fi
 # Set Hostname
 IP=<code>facter ipaddress</code>
 MY_HOST=<code>/bin/ipcalc --silent --hostname ${IP} | cut -f2 -d=</code>
 hostname ${MY_HOST}</p>
  </li>
</ol>

<p>What that does is point tells your worker nodes to use controller DNS for resolving names as well as setting your hostname.</p>

<ol>
  <li>
    <p>Get the mcollective puppet plugin from <a href="http://github.com/ripienaar/mcollective-plugins/tree/master/agent/puppetd/">github</a></p>
  </li>
  <li>
    <p>Image it</p>
  </li>
</ol>

<h2 id="bringing-up-the-environment">Bringing up the environment</h2>

<p>You will need to start the master instance first since that’s the instance that everyone will be talking to. As soon as it’s up you can start up as many instances as you’d like.</p>

<p>While you wait rsync your puppet manifests and configurations to the master node</p>

<p>To find out what nodes are up and available issue mc-ping from the master and you should get a response similar to this</p>

<pre><code># mc-ping
controller.ec2.domain.com               time=77.21 ms
domu-12-31-55-11-22-18.compute-1.internal time=188.76 ms
</code></pre>

<p>Trouble is that hostnames on the worker nodes are set to Amazon names. We want to make them recognizable e.g. mail01.</p>

<p>To do so simply add the IP of the worker instance and it’s name into /etc/hosts on the master e.g.</p>

<pre><code>echo "10.1.2.3      mail01.ec2.domain.com" &gt;&gt; /etc/hosts
</code></pre>

<p>Reload dnsmasq configuration ie.</p>

<pre><code>/etc/init.d/dnsmasq reload
</code></pre>

<p>What this has bought you is reverse DNS resolution of the node.  To take effect you will need to reboot the worker node. We already have the reboot agent on the worker nodes so all we have to do is run following command on the master node</p>

<pre><code>./mc-rpc -F hostname=domu-12-31-55-11-22-18 reboot reboot
</code></pre>

<p>This will seek out the domU-1-2-3-4 host and reboot it (–arg is irrelevant so put anything). Once the machine is up it will advertise it’s new name :-) ie. running mc-ping will show you this</p>

<pre><code># mc-ping
controller.ec2.domain.com           time=47.59 ms
mail01.ec2.domain.com               time=80.71 ms
</code></pre>

<p>Now let’s activate puppet. From master node run</p>

<pre><code># mc-puppetd -F hostname=mail01 runonce

 * [ ============================================================&gt; ] 1 / 1

Finished processing 1 / 1 hosts in 1051.23 ms
</code></pre>

<p>Once that is done puppetca should give you this</p>

<pre><code># puppetca --list
mail01.ec2.domain.com
</code></pre>

<p>Sign it</p>

<pre><code># puppetca –sign mail01.ec2.domain.com
</code></pre>

<p>Now you can simply run</p>

<pre><code># mc-puppetd -F hostname=mail01 enable
</code></pre>

<p>and off you go. Now lather, rinse, repeat to get the rest of the instances going. You would certainly want to automate this further but I leave that exercise to you :-).</p>

<p>If you are looking for an easy cross-cloud API check out my “<a href="http://blog.vuksan.com/2010/07/20/provision-to-cloud-in-5-minutes-using-fog/">Provision to cloud in 5 minutes using fog</a>”.</p>
